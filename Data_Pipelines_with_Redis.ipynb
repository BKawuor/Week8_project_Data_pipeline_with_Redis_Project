{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Background Information\n",
        "As a telecommunications data engineer, you have been tasked with building a pipeline that can efficiently extract, transform, and load data from CSV files into a Postgres database. The data to be extracted is related to customer call logs, which contain information about the duration, cost, and destination of customer calls. The extracted data needs to be transformed to ensure it is in\n",
        "the correct format and structure for storage in the database.The pipeline should also cache data using Redis to speed up the data extraction and transformation."
      ],
      "metadata": {
        "id": "V_ZgG5zlM5ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsEb0M6wMiTm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "import redis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redis Cloud Instance Information\n",
        "redis_host = 'redis-15321.c114.us-east-1-4.ec2.cloud.redislabs.com'\n",
        "redis_port = 15321\n",
        "redis_password = 'TqekLaZlH3TxkTqekLaZlH3TxkadUi'\n",
        "\n",
        "# Postgres Database Information\n",
        "pg_host = '22.237.226.11'\n",
        "pg_database = 'redisproj_db'\n",
        "pg_user = 'root'\n",
        "pg_password = 'root@123'\n",
        "\n",
        "# Redis Client Object\n",
        "redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password)\n",
        "\n",
        "def extract_data():\n",
        "    # Extract data from CSV file using pandas\n",
        "    data = pd.read_csv('cust_call_logs.csv')\n",
        "\n",
        "    # Cache data in Redis for faster retrieval\n",
        "    redis_client.set('cust_call_logs', data.to_json())\n",
        ""
      ],
      "metadata": {
        "id": "6OXePIo7M7TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming data\n",
        "\n",
        "def transform_data():\n",
        "    # Retrieve data from Redis cache\n",
        "    #filename = \"cust_call_logs.csv\"\n",
        "    #with open(filename.decode('utf-8'), 'r') as f:\n",
        "    #data = pd.read_json(redis_client.get('cust_call_logs.csv'))\n",
        "    data_bytes = redis_client.get('cust_call_logs')\n",
        "    data_decode = data_bytes.decode('utf-8')\n",
        "    data = pd.read_json(data_decode)\n",
        "\n",
        "\n",
        "    # Transform data (clean, structure, format)\n",
        "    transformed_data = data.copy()\n",
        "    transformed_data['call_cost_usd'] = transformed_data['call_cost'].str.replace('$', '').astype(float)\n",
        "    transformed_data['call_date'] = pd.to_datetime(transformed_data['call_date'])\n",
        "    transformed_data['call_duration_min'] = pd.to_timedelta(transformed_data['call_duration']).dt.total_seconds() / 60.0\n",
        "    transformed_data = transformed_data[['customer_id', 'call_cost_usd', 'call_destination', 'call_date', 'call_duration_min']]\n",
        "\n",
        "    return transformed_data"
      ],
      "metadata": {
        "id": "E3b2W31mNH8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load Data\n",
        "def load_data(transformed_data):\n",
        "    # Connect to Postgres database\n",
        "    conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)\n",
        "\n",
        "    # Create a cursor object\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Create a table to store the data\n",
        "    cur.execute('CREATE TABLE IF NOT EXISTS cust_call_logs (customer_id INT,call_cost_usd FLOAT,call_destination VARCHAR,call_date TIMESTAMP,call_duration_min FLOAT)')\n",
        "\n",
        "    # Insert the transformed data into the database\n",
        "    for i, row in transformed_data.iterrows():\n",
        "        cur.execute(f\"INSERT INTO cust_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost_usd']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})\")\n",
        "\n",
        "    # Commit the changes\n",
        "    conn.commit()\n",
        "\n",
        "    # Close the cursor and connection\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def data_pipeline():\n",
        "    # Data pipeline function\n",
        "    extract_data()\n",
        "    transformed_data = transform_data()\n",
        "    load_data(transformed_data)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Run the data pipeline function\n",
        "    data_pipeline()"
      ],
      "metadata": {
        "id": "y42sYXuYNPUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}